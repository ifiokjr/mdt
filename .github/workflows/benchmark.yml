name: benchmark

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}

jobs:
  benchmark:
    name: benchmark (baseline vs candidate)
    runs-on: ubuntu-latest
    timeout-minutes: 90
    container:
      image: rust:1.86.0-bookworm
    env:
      BENCH_ITERATIONS: "7"
      BENCH_WARMUP: "2"
      BENCH_FILE_COUNT: "200"
      BENCH_RELATIVE_THRESHOLD_PCT: "8"
      BENCH_ABSOLUTE_THRESHOLD_MS: "5"
    steps:
      - name: checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event_name == 'pull_request' && github.event.pull_request.head.sha || github.sha }}

      - name: mark workspace as safe for git
        shell: bash
        run: |
          git config --global --add safe.directory "${GITHUB_WORKSPACE}"

      - name: install benchmark dependencies
        run: |
          apt-get update
          apt-get install -y --no-install-recommends jq

      - name: cache rust dependencies
        uses: Swatinem/rust-cache@v2

      - name: determine benchmark refs
        id: refs
        shell: bash
        run: |
          set -euo pipefail

          candidate_ref="$(git rev-parse HEAD)"

          if [[ "${GITHUB_EVENT_NAME}" == "pull_request" ]]; then
            git fetch --no-tags --prune --depth=1 origin main
            baseline_ref="$(git merge-base "${candidate_ref}" origin/main)"
          else
            if git rev-parse "${candidate_ref}^" >/dev/null 2>&1; then
              baseline_ref="$(git rev-parse "${candidate_ref}^")"
            else
              baseline_ref="${candidate_ref}"
            fi
          fi

          echo "candidate_ref=${candidate_ref}" >> "${GITHUB_OUTPUT}"
          echo "baseline_ref=${baseline_ref}" >> "${GITHUB_OUTPUT}"

          echo "candidate_ref=${candidate_ref}"
          echo "baseline_ref=${baseline_ref}"

      - name: create worktrees
        id: worktrees
        shell: bash
        run: |
          set -euo pipefail

          benchmark_root="$(mktemp -d /tmp/mdt-benchmark-XXXXXX)"
          baseline_dir="${benchmark_root}/baseline"
          candidate_dir="${benchmark_root}/candidate"

          git worktree add --detach "${baseline_dir}" "${{ steps.refs.outputs.baseline_ref }}"
          git worktree add --detach "${candidate_dir}" "${{ steps.refs.outputs.candidate_ref }}"

          echo "benchmark_root=${benchmark_root}" >> "${GITHUB_OUTPUT}"
          echo "baseline_dir=${baseline_dir}" >> "${GITHUB_OUTPUT}"
          echo "candidate_dir=${candidate_dir}" >> "${GITHUB_OUTPUT}"

      - name: build baseline and candidate binaries
        id: build
        shell: bash
        run: |
          set -euo pipefail

          baseline_target="${{ steps.worktrees.outputs.benchmark_root }}/target-baseline"
          candidate_target="${{ steps.worktrees.outputs.benchmark_root }}/target-candidate"

          CARGO_TARGET_DIR="${baseline_target}" cargo build --release --locked --manifest-path "${{ steps.worktrees.outputs.baseline_dir }}/mdt_cli/Cargo.toml"
          CARGO_TARGET_DIR="${candidate_target}" cargo build --release --locked --manifest-path "${{ steps.worktrees.outputs.candidate_dir }}/mdt_cli/Cargo.toml"

          baseline_bin="${baseline_target}/release/mdt"
          candidate_bin="${candidate_target}/release/mdt"

          echo "baseline_bin=${baseline_bin}" >> "${GITHUB_OUTPUT}"
          echo "candidate_bin=${candidate_bin}" >> "${GITHUB_OUTPUT}"

      - name: run benchmark suite
        shell: bash
        run: |
          set -euo pipefail

          mkdir -p benchmark-results

          scripts/benchmark/run_suite.sh \
            --binary "${{ steps.build.outputs.baseline_bin }}" \
            --output benchmark-results/baseline.json \
            --label "baseline:${{ steps.refs.outputs.baseline_ref }}" \
            --iterations "${BENCH_ITERATIONS}" \
            --warmup "${BENCH_WARMUP}" \
            --files "${BENCH_FILE_COUNT}" \
            --workdir "${{ steps.worktrees.outputs.benchmark_root }}/suite-baseline"

          scripts/benchmark/run_suite.sh \
            --binary "${{ steps.build.outputs.candidate_bin }}" \
            --output benchmark-results/candidate.json \
            --label "candidate:${{ steps.refs.outputs.candidate_ref }}" \
            --iterations "${BENCH_ITERATIONS}" \
            --warmup "${BENCH_WARMUP}" \
            --files "${BENCH_FILE_COUNT}" \
            --workdir "${{ steps.worktrees.outputs.benchmark_root }}/suite-candidate"

      - name: compare baseline and candidate
        id: compare
        shell: bash
        run: |
          set -euo pipefail

          scripts/benchmark/compare_results.sh \
            --baseline benchmark-results/baseline.json \
            --candidate benchmark-results/candidate.json \
            --output benchmark-results/compare.json \
            --markdown benchmark-results/compare.md \
            --relative-threshold-pct "${BENCH_RELATIVE_THRESHOLD_PCT}" \
            --absolute-threshold-ms "${BENCH_ABSOLUTE_THRESHOLD_MS}"

          echo "status=$(jq -r '.status' benchmark-results/compare.json)" >> "${GITHUB_OUTPUT}"
          echo "regression_count=$(jq -r '.regression_count' benchmark-results/compare.json)" >> "${GITHUB_OUTPUT}"
          echo "improvement_count=$(jq -r '.improvement_count' benchmark-results/compare.json)" >> "${GITHUB_OUTPUT}"
          echo "missing_count=$(jq -r '.missing_count' benchmark-results/compare.json)" >> "${GITHUB_OUTPUT}"

      - name: publish benchmark summary
        if: always()
        shell: bash
        run: |
          {
            echo "# Benchmark Results"
            echo
            echo "- Baseline ref: \`${{ steps.refs.outputs.baseline_ref }}\`"
            echo "- Candidate ref: \`${{ steps.refs.outputs.candidate_ref }}\`"
            echo
            if [[ -f benchmark-results/compare.md ]]; then
              cat benchmark-results/compare.md
            else
              echo "Benchmark comparison report was not generated."
            fi
          } >> "${GITHUB_STEP_SUMMARY}"

      - name: upload benchmark artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.run_id }}-${{ github.run_attempt }}
          path: benchmark-results
          retention-days: 90

      - name: comment benchmark report on PR
        if: github.event_name == 'pull_request' && hashFiles('benchmark-results/compare.md') != ''
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            const marker = '<!-- mdt-benchmark-report -->';
            const report = fs.readFileSync('benchmark-results/compare.md', 'utf8');
            const body = `${marker}\n## Benchmark Report\n\n${report}`;

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              per_page: 100,
            });

            const existing = comments.find((comment) => comment.body?.includes(marker));

            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body,
              });
            }

      - name: enforce benchmark policy
        shell: bash
        run: |
          set -euo pipefail

          regression_count="${{ steps.compare.outputs.regression_count }}"

          if (( regression_count == 0 )); then
            echo "No regressions above threshold."
            exit 0
          fi

          if [[ "${GITHUB_EVENT_NAME}" != "pull_request" ]]; then
            echo "::error::Detected ${regression_count} benchmark regressions above threshold on push event."
            exit 1
          fi

          pr_body="$(jq -r '.pull_request.body // ""' "${GITHUB_EVENT_PATH}")"

          justification_text="$(
            printf '%s\n' "${pr_body}" | awk '
              BEGIN { capture = 0 }
              /^##[[:space:]]+Benchmark Justification[[:space:]]*$/ { capture = 1; next }
              /^##[[:space:]]+/ && capture == 1 { capture = 0 }
              capture == 1 { print }
            '
          )"

          justification_text="$(printf '%s\n' "${justification_text}" | sed '/^[[:space:]]*$/d')"

          if [[ -z "${justification_text}" ]]; then
            echo "::error::Detected ${regression_count} benchmark regressions above threshold. Add a '## Benchmark Justification' section to the PR description explaining the tradeoff."
            exit 1
          fi

          echo "Benchmark regressions detected but justification section is present in PR description."

      - name: clean up worktrees
        if: always()
        shell: bash
        run: |
          set +e

          benchmark_root="${{ steps.worktrees.outputs.benchmark_root }}"
          baseline_dir="${{ steps.worktrees.outputs.baseline_dir }}"
          candidate_dir="${{ steps.worktrees.outputs.candidate_dir }}"

          if [[ -n "${baseline_dir}" ]]; then
            git worktree remove --force "${baseline_dir}" || true
          fi
          if [[ -n "${candidate_dir}" ]]; then
            git worktree remove --force "${candidate_dir}" || true
          fi
          if [[ -n "${benchmark_root}" ]]; then
            rm -rf "${benchmark_root}" || true
          fi
